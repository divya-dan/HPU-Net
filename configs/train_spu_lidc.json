{
  "seed": 42,
  "total_steps": 240000,
  "batch_size": 16,
  "lr": 0.00005,
  "lr_milestones": [48000, 96000, 144000, 192000, 216000],
  "lr_gamma": 0.5,
  "optimizer": "adam",
  "weight_decay": 0.00001,
  "use_topk": false,
  "recon_strategy": "random",
  "eval_every_steps": 5000,
  "ckpt_every_steps": 10000,
  "num_workers": 4,
  "augment": true,
  "pos_weight": "auto",
  "pos_weight_clip": 20.0
}
